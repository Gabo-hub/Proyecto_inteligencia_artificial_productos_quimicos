# QuimicAI üß™

Asistente inteligente especializado en productos qu√≠micos dom√©sticos, desarrollado con IA para proporcionar informaci√≥n segura y √∫til sobre ingredientes, recetas y seguridad qu√≠mica.

## üéØ Caracter√≠sticas

- **B√∫squeda Inteligente**: Consulta informaci√≥n sobre productos qu√≠micos usando lenguaje natural
- **Base de Conocimientos**: Amplia base de datos con ingredientes qu√≠micos, recetas y reglas de seguridad
- **Interfaz de Chat**: Interfaz web moderna con historial de conversaciones
- **IA Local**: Utiliza Ollama con LLaMA para respuestas precisas y privadas
- **Persistencia**: Las conversaciones se guardan autom√°ticamente en el navegador

## üöÄ Instalaci√≥n

### Requisitos Previos

1. **Python 3.8+**
2. **Ollama** instalado y corriendo ([instalar Ollama](https://ollama.ai))
3. **Modelo LLaMA**:
   ```bash
   ollama pull llama3.2:3b
   ```

### Pasos de Instalaci√≥n

1. **Clonar el repositorio**:
   ```bash
   git clone <repository-url>
   cd Proyecto_inteligencia_artificial_productos_quimicos
   ```

2. **Crear entorno virtual**:
   ```bash
   python -m venv env
   ```

3. **Activar entorno virtual**:
   - Windows:
     ```powershell
     .\env\Scripts\Activate.ps1
     ```
   - Linux/Mac:
     ```bash
     source env/bin/activate
     ```

4. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   ```

5. **Configurar variables de entorno** (opcional):
   ```bash
   cp .env.example .env
   # Editar .env seg√∫n sea necesario
   ```

## ‚ñ∂Ô∏è Uso

### Iniciar el Servidor

```bash
python backend/run.py
```

El servidor estar√° disponible en `http://localhost:5000`

### Usar la Aplicaci√≥n

1. Abrir navegador en `http://localhost:5000`
2. Escribir consultas sobre productos qu√≠micos, por ejemplo:
   - "Vinagre Blanco"
   - "¬øC√≥mo hago un limpiador casero?"
   - "¬øPuedo mezclar cloro con vinagre?"
3. Las conversaciones se guardan autom√°ticamente

## üîß Configuraci√≥n

### Variables de Entorno

Crear un archivo `.env` basado en `.env.example`:

```env
# Modelo Ollama
OLLAMA_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434

# Servidor Flask
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_DEBUG=True

# Timeouts
LLM_TIMEOUT=30
```

## üß™ Testing

```bash
# Ejecutar todos los tests
python -m pytest tests/ -v

# Test espec√≠fico
python tests/test_api.py
```

## üèóÔ∏è Arquitectura

### Backend

- **Flask**: Servidor web y API REST
- **LangChain**: Framework para aplicaciones con LLM
- **Ollama**: Ejecuci√≥n local de modelos de IA
- **FAISS**: Vector store para b√∫squeda sem√°ntica

### Frontend

- **HTML/CSS/JavaScript**: Interfaz web responsiva
- **localStorage**: Persistencia de conversaciones
- **Fetch API**: Comunicaci√≥n con el backend

### Flujo de Datos

1. Usuario env√≠a pregunta desde la interfaz web
2. Frontend env√≠a request a `/api/ask`
3. Backend procesa la pregunta:
   - Busca documentos relevantes usando FAISS
   - Genera respuesta con LLaMA via Ollama
4. Respuesta se env√≠a al frontend y se muestra al usuario

## üìù API Endpoints

### `POST /api/ask`

Procesa una pregunta del usuario.

**Request:**
```json
{
  "question": "¬øQu√© es el vinagre blanco?"
}
```

**Response:**
```json
{
  "answer": "El vinagre blanco es...",
  "sources": [
    {"source": "inventario", "id": "ing_001"}
  ]
}
```

### `GET /api/health`

Health check del servicio.

**Response:**
```json
{
  "status": "ok",
  "assistant_ready": true
}
```

## ü§ù Contribuir

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## üìÑ Licencia

Este proyecto es de c√≥digo abierto y est√° disponible bajo la licencia MIT.

## ‚ö†Ô∏è Advertencias

- Este asistente proporciona informaci√≥n general sobre productos qu√≠micos
- Siempre verificar informaci√≥n de seguridad con fuentes oficiales
- Usar equipo de protecci√≥n apropiado al trabajar con qu√≠micos
- En caso de emergencia, contactar servicios m√©dicos profesionales

## üë• Autores

Proyecto Universitario - Inteligencia Artificial y Productos Qu√≠micos:

- Gabriel G√≥mez
- Armando Martinez
- Mar√≠a Malav√© 
- Dariana Medina 
- Harlys Aguilar 
- Jhostin Vargas  
- Juan Yciarte 

## üôè Agradecimientos

- Ollama por proporcionar modelos de IA locales
- LangChain por el framework de desarrollo
- Comunidad open source