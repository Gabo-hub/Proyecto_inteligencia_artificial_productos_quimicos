# Variables de entorno para QuimicAI
# Copiar este archivo a .env y configurar según sea necesario
# Cambiamos el modelo principal a Mistral
OLLAMA_MODEL=mistral:7b-instruct

# Aseguramos de usar un buen modelo de embeddings (nomic es excelente para búsqueda semántica)
OLLAMA_EMBEDDINGS_MODEL=nomic-embed-text

# Configuración del servidor Flask
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_DEBUG=True

# Timeouts
LLM_TIMEOUT=30
